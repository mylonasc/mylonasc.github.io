---
layout: post
title: Conditional Variational Autoencoder for Wind Turbine Blade Fatigue Damage Estimation
subtitle: 
bigimg: /img/tstart288.jpg
tags: [CVAE, Wind Turbine Dlade, Fatigue]
---
# The project

Wind turbine fatigue estimation relies on running computationally expensive simulations. 
The inputs of the simulations (the windfield time-series) are **non-deterministic**: We have statistical models on how the wind 
behaves under different conditions, and we simulate these inputs prior to applying them to the turbine.
Also the complex dynamics (blade geometric non-linearity, pitch control etc) make the response even more difficult to approximate with an explicit model.
Finally, in order to make the most out of our simulations, we need to analyze fatigue on the cross-section/material level, and not simply on some so-called **hot-spot** locations, or manually decompose the damage in some intuitive basis (for example the standard practice in wind turbine blades is analyzing bending directions separately (which makes little sense in my opinion - for reasons I don't want to spend the energy to rant about right now..). 

This project was about training a VAE to sample from fatigue simulation outputs, that each one takes about 1h to finish (because of
 the geometric non-linearity of the blades - I'm not using a modal description for them) plus 10~20mins for the
 actual cycle-counting procedure in the cross-section level.

## Engineering application/motivation
There are several applications where this fast sampling procedure becomes relevant in wind turbines. Nevertheless, I'm focusing on one real-life potential application. 
Consider that you have only historical summary statistics on weather. You know for a fact, that you cannot completely reproduce the stress
 states on your structure, because you never sensed that data. This is what we call "aleatory" uncertainty - the uncertainty that comes 
from incomplete information on the problem.  Say that we have a way to sample a windfield that 
resembles statistically one that produces summary statistics like the ones we have available in the so-called *Supervision Control and Data Acquisition systems* aka **SCADA** . 
For me this is a black-box.

<div class="note">
  <h5>Short side-note:</h5>
  <p>The CVAE I'm using would be a great fit for this problem as well! I couldn't find real data to do that unfortunately, 
and it is sort-of a futile exercise to try this in simulated data, since they have pretty simple gaussian random field models.
</p>
</div>

In order to have a robust estimate on the fatigue estimation, we would have to run the simulation model for several times for each SCADA reading, say 100 times (estimate on the very low side).
So in order to perform damage accumulation for 10 minutes for **one** turbine, we would need 100 * 1h = 100h worth of simulation time!
Obviously this is not going to work - so we need something that works on the millisecond scale instead of the 1h scale to do that!
This is where the CVAE comes in: Instead of running 100 simulations, we can train a neural network that can sample the fatigue estimates and then sample from it.
Moreover, since we have some info on the operational conditions, we train the model to reproduce the accumulated damage conditional on these conditions. 

The architecture of the CVAE looks like this during training:

![computational graph of the CVAE](/img/cvaesvg.png)

where **w** is the "conditioning" inputs and **x** is the fatigue loads of the cross-section. I considered only one cross-section, because visualization is much easier with one.
Also testing convergence is easier with one! Deep generative models, although they do stuff that are hardly possible less that 5-6 years before, they are quite challenging to train.
Be warned if you try this at home! In our case, **z** is a vector of SCADA data: wind, turbullence and a parametrization of the wind velocity distribution along the height of the wind turbine.

## Training dataset and tricks
The training dataset was 2000 fatigue estimates on ~250 finite elements. I have managed to train both small models and large models with heavy regularization and annealing of the KL term and dropout rates (if that means something to you).
The smallest well-trained model I managed to train was an encoder 50/50/50 - latent 15 - 50/50/50 decoder - all relus with dropout in-between (never dissapoints!). I found it important to visually monitor the latent-space and decoded samples.
I used an L2 reconstruction loss and latent spaces that worked ranged from 5 to 15. Although I have not experimented a lot, it seems that the latent space size is not so critical. I didn't care for an interpretable latent space, and I think one should not care too much about it in engineering, especially when you see your model do what you expect it to do. For example in this application I know for a fact that there is a dependency on the cross-section fatigue distribution and blade-pitch orientation. If the CVAE model finds it, and the variations on the (physical) decoder space outputs represents what I want **and** there are no hints of over-fitting - like the reconstruction making huge jumps away from the training points we're good.

The "structure" in the latent space parameters has to do with points on the latent space not corresponding to realistic physical states. I saw a recent paper refers to this as the *"holes"* problem of VAEs [(paper: Taming VAEs)](https://arxiv.org/abs/1810.00597).
In that case, obviously, if the approximate posterior is replaced with the spherical gaussian prior, there are points that will make little sense.

After training the model, I can simply throw away all the light gray parts you see in the picture (the *"encoder"*), sample **z** from a unit gaussian, and put the conditioning variables on the *decoder* part. This is a visualization of samples of accumulated damage
equivallent loads from the CVAE, with one actual realization for the time-window for two cases:

![fatigue estimates](/img/tstart288.png)


![fatigue estimates](/img/tstart1200.png)


Notice the highly non-linear dependency on the inputs. Also the VAE returns results for the whole cross-section and not only for single points! 


## Conditional variational autoencoders - animation

Have you seen these interpolations on latent spaces of generative models with faces etc? 
In case you had a burning desire to see latent interpolations on fatigue estimates, here it is.
Actually, I'm not doing latent space interpolations, I'm changing the conditioning variables. The latent space does have an effect and it is seen on the previous plots (it gives some variation on the sampled estimates of damage equivallent loads).
For better intuition on what the CVAE learned to sample from (and why it is so cool), have a look on the following animation:
<video width="720" height="480" controls="controls">
  <source src="/img/conditional_VAE_for_wind_turbine_blade_Fatigue.mp4" type="video/mp4">
</video>

The animation is slow not because of the VAE, but because I was lazy with the implementation and I redraw and render everything with matplotlib.
I'll release the code and dataset soon. Thanx for reading, and I hope you found that interesting! 



[//]: # " # Variational Autoencoders"
[//]: # "Variational techniques in statistics have been around for some time. Relatively recently"
